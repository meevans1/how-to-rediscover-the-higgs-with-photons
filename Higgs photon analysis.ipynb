{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to rediscover the Higgs boson yourself!\n",
    "This notebook uses ATLAS Open Data http://opendata.atlas.cern to show you the steps to rediscover the Higgs boson yourself!\n",
    "\n",
    "The datasets used in this notebook have already been filtered to include at least 2 photons per event, so that processing is quicker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER><img src=\"Hyy_feynman.pdf\" style=\"width:40%\"></CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First time setup on your computer\n",
    "This first cell only needs to be run the first time you open this notebook on your computer. \n",
    "\n",
    "If you close Jupyter and re-open on the same computer, you won't need to run this first cell again.\n",
    "\n",
    "If you open on binder, you don't need to run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade --user pip\n",
    "!{sys.executable} -m pip install -U numpy pandas uproot matplotlib --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To setup everytime\n",
    "Cell -> Run All Below\n",
    "\n",
    "to be done every time you re-open this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lmfit.models import PolynomialModel, GaussianModel\n",
    "import matplotlib.patches as mpatches # for \"Total SM & uncertainty\" merged legend handle\n",
    "from matplotlib.lines import Line2D # for dashed line in legend\n",
    "from matplotlib.ticker import MaxNLocator,AutoMinorLocator,LogLocator,LogFormatterSciNotation # for minor ticks\n",
    "import scipy.stats\n",
    "\n",
    "import labelfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumi = 0.5 # fb-1 # data_A only\n",
    "\n",
    "fraction = 1 # reduce this is you want the code to run quicker\n",
    "\n",
    "tuple_path = \"Photon_Input/Data/\" # local \n",
    "#tuple_path = \"http://opendata.atlas.cern/release/samples/2019/GamGam/\" # web address (not released yet!)\n",
    "\n",
    "stack_order = [] # put smallest contribution first, then increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {\n",
    "\n",
    "    'data': {\n",
    "        'list' : ['data_A']\n",
    "    },\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sample(s):\n",
    "    print('Processing '+s+' samples')\n",
    "    frames = []\n",
    "    for val in samples[s]['list']:\n",
    "        fileString = tuple_path+val+\".GamGam.root\" # change ending depending on collection used, e.g. .4lep.root\n",
    "        if fileString != \"\":\n",
    "            temp = read_file(fileString,val)\n",
    "            frames.append(temp)\n",
    "        else:\n",
    "            print(\"Error: \"+val+\" not found!\")\n",
    "    data_s = pd.concat(frames)\n",
    "    return data_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_files():\n",
    "\n",
    "    data = {}\n",
    "    for s in samples:\n",
    "        data[s] = read_sample(s)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_myy(photon_pt,photon_eta,photon_phi):\n",
    "    myy = 2*photon_pt[0]*photon_pt[1]\n",
    "    cosh = math.cosh(photon_eta[0]-photon_eta[1])\n",
    "    cos = math.cos(photon_phi[0]-photon_phi[1])\n",
    "    myy *= ( cosh - cos )\n",
    "    return math.sqrt(myy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing an already uncommented cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you change a cut: Cell -> Run All Below\n",
    "\n",
    "If you uncomment a cut here, you also need to uncomment the corresponding cut in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut on number of photons\n",
    "# paper: \"The data used in this channel are selected using a diphoton trigger, which requires two clusters\"\n",
    "def cut_photon_n (photon_n):\n",
    "# want to discard any events where photon_n does not equal 2\n",
    "    # exclamation mark (!) means \"not\"\n",
    "    # so != means \"not equal to\"\n",
    "    return photon_n != 2\n",
    "\n",
    "# Cut on pseudorapidity outside the fiducial region\n",
    "# paper: \"Photon candidates are reconstructed in the fiducial region |η| < 2.37\"\n",
    "def cut_photon_eta_fiducial(photon_eta):\n",
    "# want to discard any events where modulus of photon_eta > 2.37\n",
    "    return photon_eta[0] > 2.37 or photon_eta[1] > 2.37 or photon_eta[0] < -2.37 or photon_eta[1] < -2.37\n",
    "\n",
    "# Cut on pseudorapidity in barrel/end-cap transition region\n",
    "# paper: \"excluding the calorimeter barrel/end-cap transition region 1.37 <􏰈 |η| < 1.52\"\n",
    "def cut_photon_eta_transition(photon_eta):\n",
    "# want to discard events where modulus of photon_eta between 1.37 and 1.52\n",
    "    if photon_eta[0] < 1.52 and photon_eta[0] > 1.37: return True\n",
    "    elif photon_eta[1] < 1.52 and photon_eta[1] > 1.37: return True\n",
    "    elif photon_eta[0] > -1.52 and photon_eta[0] < -1.37: return True\n",
    "    elif photon_eta[1] < -1.37 and photon_eta[1] > -1.52: return True\n",
    "    else: return False\n",
    "    \n",
    "# Cut on Transverse momentum\n",
    "# paper: \"The leading (sub-leading) photon candidate is required to have ET > 40 GeV (30 GeV)\"\n",
    "def cut_photon_pt(photon_pt):\n",
    "# want to discard any events where photon_pt[0] < 40000 MeV or photon_pt[1] < 30000 MeV\n",
    "    # first lepton is [0], 2nd lepton is [1] etc\n",
    "    return photon_pt[0] < 40000 or photon_pt[1] < 30000\n",
    "\n",
    "# Cut on photon reconstruction\n",
    "# paper: \"Photon candidates are required to pass identification criteria\"\n",
    "def cut_photon_reconstruction(photon_isTightID):\n",
    "# want to discard events where it is false for one or both photons\n",
    "    return photon_isTightID[0] == False or photon_isTightID[1] == False\n",
    "\n",
    "# Cut on energy isolation\n",
    "# paper: \"Photon candidates are required to have an isolation transverse energy of less than 4 GeV\"\n",
    "def cut_isolation_et(photon_etcone20):\n",
    "# want to discard events where isolation eT > 4000 MeV\n",
    "    return photon_etcone20[0] > 4000 or photon_etcone20[1] > 4000\n",
    "    \n",
    "# Cut on reconstructed invariant mass lower limit\n",
    "# paper: \"in the diphoton invariant mass range between 100 GeV and 160 GeV\"\n",
    "def cut_mass_lower(myy):\n",
    "# want to discard minimum invariant reconstructed mass < 100 GeV\n",
    "    return myy < 100*1000 #*1000 to go from GeV to MeV\n",
    "\n",
    "# Cut on reconstructed invariant mass upper limit\n",
    "# paper: \"in the diphoton invariant mass range between 100 GeV and 160 GeV\"\n",
    "def cut_mass_upper(myy):\n",
    "# want to discard maximum invariant reconstructed mass > 160 GeV\n",
    "    return myy > 160*1000 #*1000 to go from GeV to MeV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncommenting a new cut \n",
    "\n",
    "If you add a cut: Cell -> Run All Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path,sample):\n",
    "    start = time.time()\n",
    "    print(\"\\tProcessing: \"+sample)\n",
    "    data_all = pd.DataFrame()\n",
    "    mc = uproot.open(path)[\"mini\"]\n",
    "    numevents = uproot.numentries(path, \"mini\")\n",
    "    for data in mc.iterate([\"photon_n\",\"photon_trigMatched\",\"photon_pt\",\"photon_eta\",\"photon_phi\",\"photon_isTightID\",\n",
    "                         \"photon_etcone20\"], flatten=False, entrysteps=2500000, outputtype=pd.DataFrame, entrystop=numevents*fraction):\n",
    "\n",
    "        nIn = len(data.index)\n",
    "\n",
    "        # Calculate reconstructed diphoton invariant mass\n",
    "        data['myy'] = np.vectorize(calc_myy)(data.photon_pt,data.photon_eta,data.photon_phi)\n",
    "\n",
    "        # Cut on number of photons\n",
    "        fail = data[ np.vectorize(cut_photon_n)(data.photon_n)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "\n",
    "        # Cut on pseudorapidity outside fiducial region\n",
    "        fail = data[ np.vectorize(cut_photon_eta_fiducial)(data.photon_eta)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "\n",
    "        # Cut on pseudorapidity inside barrel/end-cap transition region\n",
    "        fail = data[ np.vectorize(cut_photon_eta_transition)(data.photon_eta)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "\n",
    "        # Cut on transverse momentum of the photons\n",
    "        fail = data[ np.vectorize(cut_photon_pt)(data.photon_pt)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "\n",
    "        # Cut on photon reconstruction\n",
    "        fail = data[ np.vectorize(cut_photon_reconstruction)(data.photon_isTightID)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "\n",
    "        # Cut on energy isolation\n",
    "        fail = data[ np.vectorize(cut_isolation_et)(data.photon_etcone20)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "\n",
    "        # Cut on lower limit of reconstructed invariant mass\n",
    "        fail = data[ np.vectorize(cut_mass_lower)(data.myy)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "\n",
    "        # Cut on upper limit of reconsructed invariant mass\n",
    "        fail = data[ np.vectorize(cut_mass_upper)(data.myy)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "\n",
    "        # dataframe contents can be printed at any stage like this\n",
    "        #print(data)\n",
    "\n",
    "        # dataframe column can be printed at any stage like this\n",
    "        #print(data['photon_pt'])\n",
    "\n",
    "        # dataframe columns can be printed at any stage like this\n",
    "        #print(data[['photon_pt','photon_eta']])\n",
    "\n",
    "        nOut = len(data.index)\n",
    "        data_all = data_all.append(data)\n",
    "        elapsed = time.time() - start\n",
    "        print(\"\\t\\tTime taken: \"+str(elapsed)+\", nIn: \"+str(nIn)+\", nOut: \"+str(nOut))\n",
    "    \n",
    "    return data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "data = get_data_from_files()\n",
    "elapsed = time.time() - start\n",
    "print(\"Time taken: \"+str(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a change to plotting\n",
    "If you only want a make a change in the plot: Cell -> Run All Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myy = {\n",
    "    # change plotting parameters                                                                                                     \n",
    "    'bin_width':2,\n",
    "    'num_bins':30,\n",
    "    'xrange_min':100,\n",
    "    'log_y':False,\n",
    "\n",
    "    # change aesthetic parameters if you want                                                                                        \n",
    "    'y_label_x_position':-0.09, # 0.09 to the left of y axis                                                                         \n",
    "    'legend_loc':'lower left',\n",
    "    'log_top_margin':10000, # to decrease the separation between data and the top of the figure, remove a 0                          \n",
    "    'linear_top_margin':1.1 # to decrease the separation between data and the top of the figure, pick a number closer to 1           \n",
    "}\n",
    "\n",
    "hist_dict = {'myy':myy} # add a histogram here if you want it plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data):\n",
    "    \n",
    "    signal_format = None # 'line' or 'hist' or None\n",
    "    Total_SM_label = False # for Total SM black line in plot and legend\n",
    "    plot_label = r'$H \\rightarrow \\gamma\\gamma$'\n",
    "    signal_label = ''\n",
    "    \n",
    "    # *******************\n",
    "    # general definitions (shouldn't need to change)\n",
    "    lumi_used = str(lumi*fraction)    \n",
    "    signal = None\n",
    "    for s in samples.keys():\n",
    "        if s not in stack_order and s!='data': signal = s\n",
    "\n",
    "    for x_variable,hist in hist_dict.items():\n",
    "\n",
    "        h_bin_width = hist['bin_width']\n",
    "        h_num_bins = hist['num_bins']\n",
    "        h_xrange_min = hist['xrange_min']\n",
    "        h_log_y = hist['log_y']\n",
    "        h_y_label_x_position = hist['y_label_x_position']\n",
    "        h_legend_loc = hist['legend_loc']\n",
    "        h_log_top_margin = hist['log_top_margin'] # to decrease the separation between data and the top of the figure, remove a 0\n",
    "        h_linear_top_margin = hist['linear_top_margin'] # to decrease the separation between data and the top of the figure, pick a number closer to 1\n",
    "\n",
    "        bins = [h_xrange_min + x*h_bin_width for x in range(h_num_bins+1) ]\n",
    "        bin_centres = [h_xrange_min+h_bin_width/2 + x*h_bin_width for x in range(h_num_bins) ]\n",
    "\n",
    "        data_x,_ = np.histogram(data['data'][x_variable].values/1000, bins=bins)\n",
    "        data_x_errors = np.sqrt(data_x)\n",
    "    \n",
    "        # data fit\n",
    "        polynomial_mod = PolynomialModel(4)\n",
    "        gaussian_mod = GaussianModel()\n",
    "        bin_centres_array = np.asarray(bin_centres)\n",
    "        pars = polynomial_mod.guess(data_x, x=bin_centres_array, c0=data_x.max(), c1=0, c2=0, c3=0, c4=0)\n",
    "        pars += gaussian_mod.guess(data_x, x=bin_centres_array, amplitude=91.7, center=125., sigma=2.4)\n",
    "        model = polynomial_mod + gaussian_mod\n",
    "        out = model.fit(data_x, pars, x=bin_centres_array, weights=1/data_x_errors)\n",
    "    \n",
    "        # background part of fit\n",
    "        params_dict = out.params.valuesdict()\n",
    "        c0 = params_dict['c0']\n",
    "        c1 = params_dict['c1']\n",
    "        c2 = params_dict['c2']\n",
    "        c3 = params_dict['c3']\n",
    "        c4 = params_dict['c4']\n",
    "        background = c0 + c1*bin_centres_array + c2*bin_centres_array**2 + c3*bin_centres_array**3 + c4*bin_centres_array**4\n",
    "\n",
    "        signal_x = None\n",
    "        if signal_format=='line':\n",
    "            signal_x,_ = np.histogram(data[signal][x_variable].values/1000,bins=bins,weights=data[signal].totalWeight.values)\n",
    "        elif signal_format=='hist':\n",
    "            signal_x = data[signal][x_variable].values/1000\n",
    "            signal_weights = data[signal].totalWeight.values\n",
    "            signal_color = samples[signal]['color']\n",
    "        signal_x = data_x - background\n",
    "    \n",
    "        mc_x = []\n",
    "        mc_weights = []\n",
    "        mc_colors = []\n",
    "        mc_labels = []\n",
    "        mc_x_tot = np.zeros(len(bin_centres))\n",
    "\n",
    "        for s in stack_order:\n",
    "            mc_labels.append(s)\n",
    "            mc_x.append(data[s][x_variable].values/1000)\n",
    "            mc_colors.append(samples[s]['color'])\n",
    "            mc_weights.append(data[s].totalWeight.values)\n",
    "            mc_x_heights,_ = np.histogram(data[s][x_variable].values/1000,bins=bins,weights=data[s].totalWeight.values)\n",
    "            mc_x_tot = np.add(mc_x_tot, mc_x_heights)\n",
    "    \n",
    "        mc_x_err = np.sqrt(mc_x_tot)\n",
    "    \n",
    "    \n",
    "        # *************\n",
    "        # Main plot \n",
    "        # *************\n",
    "        plt.axes([0.1,0.3,0.85,0.65]) #(left, bottom, width, height)\n",
    "        main_axes = plt.gca()\n",
    "        main_axes.errorbar( x=bin_centres, y=data_x, yerr=data_x_errors, fmt='ko', label='Data')\n",
    "        if Total_SM_label:\n",
    "            totalSM_handle, = main_axes.step(bins,np.insert(mc_x_tot,0,mc_x_tot[0]),color='black')\n",
    "        if signal_format=='line':\n",
    "            main_axes.step(bins,np.insert(signal_x,0,signal_x[0]),color=samples[signal]['color'], linestyle='--',\n",
    "                       label=signal)\n",
    "        elif signal_format=='hist':\n",
    "            main_axes.hist(signal_x,bins=bins,bottom=mc_x_tot,weights=signal_weights,color=signal_color,label=signal)\n",
    "        main_axes.bar(bin_centres,2*mc_x_err,bottom=mc_x_tot-mc_x_err,alpha=0.5,color='none',hatch=\"////\",\n",
    "                  width=h_bin_width, label='Stat. Unc.')\n",
    "        main_axes.plot(bin_centres, out.best_fit, '-r', label='Sig+Bkg Fit ($m_H=125$ GeV)')\n",
    "        main_axes.plot(bin_centres, background, '--r', label='Bkg (4th order polynomial)')\n",
    "        \n",
    "        main_axes.set_xlim(left=h_xrange_min,right=bins[-1])\n",
    "        main_axes.xaxis.set_minor_locator(AutoMinorLocator()) # separation of x axis minor ticks\n",
    "        main_axes.tick_params(which='both',direction='in',top=True,labeltop=False,labelbottom=False,right=True,labelright=False)\n",
    "        main_axes.set_ylabel(r'Events / '+str(h_bin_width)+r' GeV',fontname='sans-serif',horizontalalignment='right',y=1.0,fontsize=11)\n",
    "        if h_log_y:\n",
    "            main_axes.set_yscale('log')\n",
    "            smallest_contribution = mc_heights[0][0]\n",
    "            smallest_contribution.sort()\n",
    "            bottom = smallest_contribution[-2]\n",
    "            top = np.amax(data_x)*h_log_top_margin\n",
    "            main_axes.set_ylim(bottom=bottom,top=top)\n",
    "            main_axes.yaxis.set_major_formatter(CustomTicker())\n",
    "            locmin = LogLocator(base=10.0,subs=(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9),numticks=12)\n",
    "            main_axes.yaxis.set_minor_locator(locmin)\n",
    "        else: \n",
    "            main_axes.set_ylim(bottom=0,top=(np.amax(data_x)+math.sqrt(np.amax(data_x)))*h_linear_top_margin)\n",
    "            main_axes.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "            main_axes.yaxis.get_major_ticks()[0].set_visible(False)\n",
    "        \n",
    "        plt.text(0.2,0.97,'ATLAS',ha=\"left\",va=\"top\",family='sans-serif',transform=main_axes.transAxes,style='italic',weight='bold',fontsize=13)\n",
    "        plt.text(0.34,0.97,'Open Data',ha=\"left\",va=\"top\",family='sans-serif',transform=main_axes.transAxes,fontsize=13)\n",
    "        plt.text(0.2,0.9,'for education only',ha=\"left\",va=\"top\",family='sans-serif',transform=main_axes.transAxes,style='italic',fontsize=8)\n",
    "        plt.text(0.2,0.86,r'$\\sqrt{s}=13\\,\\mathrm{TeV},\\;\\int L\\,dt=$'+lumi_used+'$\\,\\mathrm{fb}^{-1}$',ha=\"left\",va=\"top\",family='sans-serif',transform=main_axes.transAxes)\n",
    "        plt.text(0.2,0.78,plot_label,ha=\"left\",va=\"top\",family='sans-serif',transform=main_axes.transAxes)\n",
    "    \n",
    "        # Create new legend handles but use the colors from the existing ones \n",
    "        handles, labels = main_axes.get_legend_handles_labels()\n",
    "        if signal_format=='line':\n",
    "            handles[labels.index(signal)] = Line2D([], [], c=samples[signal]['color'], linestyle='dashed')\n",
    "        if Total_SM_label:\n",
    "            uncertainty_handle = mpatches.Patch(facecolor='none',hatch='////')\n",
    "            handles.append((totalSM_handle,uncertainty_handle))\n",
    "            labels.append('Total SM')\n",
    "    \n",
    "        # specify order within legend\n",
    "        new_handles = [handles[labels.index('Data')]]\n",
    "        new_labels = ['Data']\n",
    "        for s in reversed(stack_order):\n",
    "            new_handles.append(handles[labels.index(s)])\n",
    "            new_labels.append(s)\n",
    "        if Total_SM_label:\n",
    "            new_handles.append(handles[labels.index('Total SM')])\n",
    "            new_labels.append('Total SM')\n",
    "        else: \n",
    "            new_handles.append(handles[labels.index('Sig+Bkg Fit ($m_H=125$ GeV)')])\n",
    "            new_handles.append(handles[labels.index('Bkg (4th order polynomial)')])\n",
    "            new_labels.append('Sig+Bkg Fit ($m_H=125$ GeV)')\n",
    "            new_labels.append('Bkg (4th order polynomial)')\n",
    "        if signal is not None:\n",
    "            new_handles.append(handles[labels.index(signal)])\n",
    "            new_labels.append(signal_label)\n",
    "        main_axes.legend(handles=new_handles, labels=new_labels, frameon=False, loc=h_legend_loc)\n",
    "    \n",
    "    \n",
    "        # *************\n",
    "        # Data-Bkg plot \n",
    "        # *************\n",
    "        plt.axes([0.1,0.1,0.85,0.2]) #(left, bottom, width, height)\n",
    "        ratio_axes = plt.gca()\n",
    "        ratio_axes.yaxis.set_major_locator(MaxNLocator(nbins='auto',symmetric=True))\n",
    "        ratio_axes.errorbar( x=bin_centres, y=signal_x, yerr=data_x_errors, fmt='ko')\n",
    "        ratio_axes.plot(bin_centres, out.best_fit-background, '-r')\n",
    "        ratio_axes.plot(bin_centres, background-background, '--r') \n",
    "        ratio_axes.set_xlim(left=h_xrange_min,right=bins[-1])\n",
    "        ratio_axes.xaxis.set_minor_locator(AutoMinorLocator()) # separation of x axis minor ticks\n",
    "        ratio_axes.xaxis.set_label_coords(0.9,-0.2) # (x,y) of x axis label # 0.2 down from x axis\n",
    "        ratio_axes.set_xlabel(labelfile.variable_labels[x_variable],fontname='sans-serif',fontsize=11)\n",
    "        ratio_axes.tick_params(which='both',direction='in',top=True,labeltop=False,right=True,labelright=False)\n",
    "        ratio_axes.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        if signal_format=='line' or signal_format=='hist':\n",
    "            ratio_axes.set_ylabel(r'Data/SM',fontname='sans-serif',x=1,fontsize=11)\n",
    "        else:\n",
    "            ratio_axes.set_ylabel(r'Events-Bkg',fontname='sans-serif',x=1,fontsize=11)\n",
    "        \n",
    "        \n",
    "        # Generic features for both plots\n",
    "        main_axes.yaxis.set_label_coords(h_y_label_x_position,1)\n",
    "        ratio_axes.yaxis.set_label_coords(h_y_label_x_position,0.5)\n",
    "    \n",
    "        plt.savefig(\"Hyy_\"+x_variable+\".pdf\")\n",
    "    \n",
    "        print('chi^2 = '+str(out.chisqr))\n",
    "        print('gaussian centre = '+str(params_dict['center']))\n",
    "        print('gaussian sigma = '+str(params_dict['sigma']))\n",
    "        print('gaussian fwhm = '+str(params_dict['fwhm']))\n",
    "    \n",
    "    return signal_x,mc_x_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_yields,background_yields = plot_data(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
